{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ReDSM5 LLM Fine-tuning on Google Colab\n",
    "\n",
    "This notebook enables training decoder-only LLMs (Llama/Qwen) with **TPU/GPU** acceleration on Google Colab.\n",
    "\n",
    "## Features\n",
    "- âœ… Automatic TPU/GPU/CPU detection\n",
    "- âœ… LoRA/QLoRA support for efficient fine-tuning\n",
    "- âœ… Multi-label DSM-5 symptom classification\n",
    "- âœ… Sliding window for long documents\n",
    "- âœ… Threshold optimization and model export\n",
    "\n",
    "## Before Starting\n",
    "1. Go to **Runtime > Change runtime type**\n",
    "2. Select **T4 GPU** or **TPU v2** for hardware accelerator\n",
    "3. Click **Save**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Installation\n",
    "print(\"ðŸ“¦ Installing dependencies...\")\n",
    "!pip install -q transformers>=4.36.0 datasets>=2.16.0 accelerate>=0.25.0\n",
    "!pip install -q peft>=0.7.0 bitsandbytes>=0.41.0 scipy scikit-learn\n",
    "!pip install -q wandb optuna pyyaml pandas matplotlib seaborn\n",
    "\n",
    "# For TPU support (optional - will be skipped if not on TPU)\n",
    "try:\n",
    "    !pip install -q cloud-tpu-client\n",
    "    !pip install -q torch-xla\n",
    "    print(\"âœ… TPU libraries installed\")\n",
    "except:\n",
    "    print(\"âš ï¸  TPU libraries not available (using GPU/CPU)\")\n",
    "\n",
    "# Clone repository\n",
    "import os\n",
    "if not os.path.exists('LLM_Agents_ReDSM5'):\n",
    "    !git clone https://github.com/OscarTsao/LLM_Agents_ReDSM5.git\n",
    "    print(\"âœ… Repository cloned\")\n",
    "else:\n",
    "    print(\"âœ… Repository already exists\")\n",
    "\n",
    "%cd LLM_Agents_ReDSM5\n",
    "print(\"\\nâœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hardware_detection"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Hardware Detection\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"ðŸ” Detecting hardware...\\n\")\n",
    "\n",
    "# Try TPU detection\n",
    "USE_TPU = False\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    device = xm.xla_device()\n",
    "    USE_TPU = True\n",
    "    print(f\"âœ… TPU detected: {device}\")\n",
    "    print(f\"   TPU cores: {xm.xrt_world_size()}\")\n",
    "except ImportError:\n",
    "    USE_TPU = False\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ… GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"   Compute capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  CPU only - training will be slow\")\n",
    "        print(\"   Recommendation: Use Runtime > Change runtime type to enable GPU/TPU\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Environment Info:\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"   TPU mode: {USE_TPU}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Mount Google Drive (Optional - for data/checkpoints)\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "MOUNT_DRIVE = False  # Set to True to use Google Drive\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = '/content/drive/MyDrive/redsm5_data'\n",
    "    OUTPUT_BASE = '/content/drive/MyDrive/redsm5_outputs'\n",
    "    print(f\"âœ… Drive mounted\")\n",
    "    print(f\"   Data directory: {DATA_DIR}\")\n",
    "    print(f\"   Output directory: {OUTPUT_BASE}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Using local storage (data will be lost after session ends)\")\n",
    "    print(\"   Set MOUNT_DRIVE=True to use Google Drive for persistent storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Generate Sample Data (or load your own)\n",
    "from pathlib import Path\n",
    "\n",
    "USE_SAMPLE_DATA = True  # Set to False if using real data\n",
    "\n",
    "if USE_SAMPLE_DATA:\n",
    "    print(\"ðŸ“ Generating synthetic sample data...\")\n",
    "    from tests.fixtures.data import generate_synthetic_dataset\n",
    "    \n",
    "    # Create sample dataset\n",
    "    DATA_DIR = Path('/content/sample_data')\n",
    "    generate_synthetic_dataset(DATA_DIR, num_samples=200, seed=42)\n",
    "    \n",
    "    print(f\"\\nâœ… Generated sample data in {DATA_DIR}\")\n",
    "    print(f\"   Train samples: 140\")\n",
    "    print(f\"   Dev samples: 30\")\n",
    "    print(f\"   Test samples: 30\")\n",
    "    print(\"\\nâš ï¸  Note: This is synthetic data for demonstration.\")\n",
    "    print(\"   For real training, set USE_SAMPLE_DATA=False and provide your data.\")\n",
    "else:\n",
    "    print(f\"ðŸ“‚ Using data from: {DATA_DIR}\")\n",
    "    # Verify data exists\n",
    "    data_dir = Path(DATA_DIR)\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        files = list(data_dir.glob(f\"{split}.*\"))\n",
    "        if files:\n",
    "            print(f\"   âœ… {split}: {files[0].name}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {split}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf_login"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Hugging Face Login (for gated models)\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "USE_GATED_MODEL = False  # Set to True if using Llama-2 or other gated models\n",
    "\n",
    "if USE_GATED_MODEL:\n",
    "    print(\"ðŸ” Please log in to Hugging Face...\")\n",
    "    notebook_login()\n",
    "    print(\"âœ… Logged in to Hugging Face\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Skipping HF login (not using gated models)\")\n",
    "    print(\"   Set USE_GATED_MODEL=True if using Llama-2 or similar models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Cell 6: Configure Training\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âš™ï¸  Configuring training parameters...\\n\")\n",
    "\n",
    "# Choose model (use smaller models for faster experimentation)\n",
    "MODEL_OPTIONS = {\n",
    "    'tiny': 'hf-internal-testing/tiny-random-LlamaForSequenceClassification',  # For testing\n",
    "    'small': 'meta-llama/Llama-2-7b-hf',  # 7B model\n",
    "    'medium': 'Qwen/Qwen2.5-7B',  # Alternative 7B\n",
    "    'large': 'meta-llama/Llama-2-13b-hf'  # 13B model\n",
    "}\n",
    "\n",
    "MODEL_SIZE = 'tiny'  # Change to 'small', 'medium', or 'large' for production\n",
    "\n",
    "config = {\n",
    "    # Model settings\n",
    "    'model_id': MODEL_OPTIONS[MODEL_SIZE],\n",
    "    'method': 'lora',  # 'full_ft', 'lora', or 'qlora'\n",
    "    \n",
    "    # Training hyperparameters (optimized for TPU/GPU)\n",
    "    'num_train_epochs': 3,\n",
    "    'per_device_train_batch_size': 8 if USE_TPU else (4 if torch.cuda.is_available() else 2),\n",
    "    'per_device_eval_batch_size': 16 if USE_TPU else (8 if torch.cuda.is_available() else 4),\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_grad_norm': 1.0,\n",
    "    \n",
    "    # LoRA settings (if method='lora' or 'qlora')\n",
    "    'lora_r': 16,\n",
    "    'lora_alpha': 32,\n",
    "    'lora_dropout': 0.05,\n",
    "    'lora_target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj'],\n",
    "    \n",
    "    # Document processing\n",
    "    'max_length': 2048 if USE_TPU else (1024 if torch.cuda.is_available() else 512),\n",
    "    'doc_stride': 512,\n",
    "    'truncation_strategy': 'window_pool',\n",
    "    'pooler': 'mean',  # 'max', 'mean', or 'logit_sum'\n",
    "    \n",
    "    # Loss settings\n",
    "    'loss_type': 'bce',  # 'bce' or 'focal'\n",
    "    'class_weighting': 'sqrt_inv',  # 'none', 'inv', or 'sqrt_inv'\n",
    "    'label_smoothing': 0.0,\n",
    "    'focal_gamma': 2.0,\n",
    "    \n",
    "    # Optimization (hardware-aware)\n",
    "    'bf16': USE_TPU or (torch.cuda.is_available() and torch.cuda.is_bf16_supported()),\n",
    "    'fp16': not USE_TPU and torch.cuda.is_available() and not torch.cuda.is_bf16_supported(),\n",
    "    'tf32': True,\n",
    "    'gradient_checkpointing': True,\n",
    "    \n",
    "    # Evaluation and checkpointing\n",
    "    'evaluation_strategy': 'epoch',\n",
    "    'save_strategy': 'epoch',\n",
    "    'save_total_limit': 2,\n",
    "    'load_best_model_at_end': True,\n",
    "    'metric_for_best_model': 'macro_f1',\n",
    "    \n",
    "    # Data\n",
    "    'data_dir': str(DATA_DIR),\n",
    "    'train_split': 'train',\n",
    "    'dev_split': 'dev',\n",
    "    'test_split': 'test',\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Optional: Limit samples for quick testing\n",
    "    # 'max_train_samples': 50,\n",
    "    # 'max_eval_samples': 20,\n",
    "}\n",
    "\n",
    "# Save config\n",
    "config_path = Path('/content/colab_config.yaml')\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"âœ… Configuration saved\\n\")\n",
    "print(\"ðŸ“‹ Key settings:\")\n",
    "print(f\"   Model: {config['model_id']}\")\n",
    "print(f\"   Method: {config['method']}\")\n",
    "print(f\"   Epochs: {config['num_train_epochs']}\")\n",
    "print(f\"   Batch size: {config['per_device_train_batch_size']}\")\n",
    "print(f\"   Max length: {config['max_length']}\")\n",
    "print(f\"   Precision: {'bf16' if config['bf16'] else ('fp16' if config['fp16'] else 'fp32')}\")\n",
    "print(f\"   Device: {'TPU' if USE_TPU else 'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Start Training\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "OUTPUT_DIR = Path('/content/outputs')\n",
    "LABELS_PATH = Path('configs/labels.yaml')\n",
    "\n",
    "print(\"ðŸš€ Starting training...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "!python -m src.train \\\n",
    "    --config {config_path} \\\n",
    "    --labels {LABELS_PATH} \\\n",
    "    --out_dir {OUTPUT_DIR} \\\n",
    "    --use_wandb false\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Training complete in {elapsed_time/60:.2f} minutes!\")\n",
    "print(f\"ðŸ“ Outputs saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results"
   },
   "outputs": [],
   "source": [
    "# Cell 8: View Training Results\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ðŸ“Š Loading training results...\\n\")\n",
    "\n",
    "# Load metrics\n",
    "metrics_path = OUTPUT_DIR / 'metrics_dev.json'\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path) as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"ðŸŽ¯ Development Set Results:\")\n",
    "    print(f\"   Macro F1:    {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"   Micro F1:    {metrics['micro_f1']:.4f}\")\n",
    "    print(f\"   Weighted F1: {metrics['weighted_f1']:.4f}\")\n",
    "    \n",
    "    # Load per-label report\n",
    "    report_path = OUTPUT_DIR / 'label_report_dev.csv'\n",
    "    if report_path.exists():\n",
    "        df = pd.read_csv(report_path)\n",
    "        print(\"\\nðŸ“‹ Per-Label Performance:\")\n",
    "        print(df[['label', 'f1', 'precision', 'recall', 'support']].to_string(index=False))\n",
    "else:\n",
    "    print(\"âŒ Metrics file not found. Training may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate on Test Set\n",
    "BEST_CKPT = OUTPUT_DIR / 'best'\n",
    "\n",
    "print(\"ðŸ§ª Evaluating on test set...\\n\")\n",
    "\n",
    "!python -m src.eval \\\n",
    "    --ckpt {BEST_CKPT} \\\n",
    "    --labels {LABELS_PATH} \\\n",
    "    --data_dir {DATA_DIR} \\\n",
    "    --split test\n",
    "\n",
    "print(\"\\nâœ… Test evaluation complete!\")\n",
    "\n",
    "# Load test metrics\n",
    "test_metrics_path = BEST_CKPT / 'eval_test' / 'metrics.json'\n",
    "if test_metrics_path.exists():\n",
    "    with open(test_metrics_path) as f:\n",
    "        test_metrics = json.load(f)\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Test Set Results:\")\n",
    "    print(f\"   Macro F1:    {test_metrics['macro_f1']:.4f}\")\n",
    "    print(f\"   Micro F1:    {test_metrics['micro_f1']:.4f}\")\n",
    "    print(f\"   Weighted F1: {test_metrics['weighted_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "# Cell 10: Visualize Predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"ðŸ“ˆ Generating visualizations...\\n\")\n",
    "\n",
    "# Load predictions\n",
    "pred_path = BEST_CKPT / 'eval_test' / 'predictions.csv'\n",
    "if pred_path.exists():\n",
    "    pred_df = pd.read_csv(pred_path)\n",
    "    \n",
    "    # Get label columns\n",
    "    label_cols = [\n",
    "        'depressed_mood', 'diminished_interest', 'weight_appetite_change',\n",
    "        'sleep_disturbance', 'psychomotor', 'fatigue',\n",
    "        'worthlessness_guilt', 'concentration_indecision', 'suicidality'\n",
    "    ]\n",
    "    \n",
    "    # Check if prediction columns exist\n",
    "    prob_cols = [f'{label}_prob' for label in label_cols]\n",
    "    if all(col in pred_df.columns for col in prob_cols):\n",
    "        # Plot 1: Probability distribution heatmap\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Heatmap of prediction probabilities\n",
    "        probs_matrix = pred_df[prob_cols].values[:50]  # First 50 samples\n",
    "        sns.heatmap(probs_matrix.T, ax=ax1, cmap='YlOrRd', \n",
    "                   yticklabels=[l.replace('_', ' ').title() for l in label_cols],\n",
    "                   xticklabels=False, cbar_kws={'label': 'Probability'})\n",
    "        ax1.set_title('Prediction Probabilities (First 50 samples)', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Sample Index')\n",
    "        ax1.set_ylabel('DSM-5 Symptom')\n",
    "        \n",
    "        # Plot 2: Average probability per label\n",
    "        avg_probs = pred_df[prob_cols].mean().values\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(label_cols)))\n",
    "        bars = ax2.barh([l.replace('_', ' ').title() for l in label_cols], avg_probs, color=colors)\n",
    "        ax2.set_xlabel('Average Probability', fontsize=12)\n",
    "        ax2.set_title('Average Prediction Probability by Symptom', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlim(0, 1)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, prob) in enumerate(zip(bars, avg_probs)):\n",
    "            ax2.text(prob + 0.02, i, f'{prob:.3f}', va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 3: Confusion-style label counts\n",
    "        if 'doc_id' in pred_df.columns:\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            # Count positive predictions per label\n",
    "            pred_counts = (pred_df[prob_cols] > 0.5).sum().values\n",
    "            \n",
    "            x = np.arange(len(label_cols))\n",
    "            ax.bar(x, pred_counts, color='steelblue', alpha=0.7, label='Predicted Positive')\n",
    "            \n",
    "            ax.set_xlabel('DSM-5 Symptom', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "            ax.set_title('Predicted Positive Cases per Symptom', fontsize=14, fontweight='bold')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([l.replace('_', ' ').title() for l in label_cols], \n",
    "                              rotation=45, ha='right')\n",
    "            ax.legend()\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"âš ï¸  Probability columns not found in predictions file\")\n",
    "else:\n",
    "    print(\"âŒ Predictions file not found\")\n",
    "\n",
    "print(\"\\nâœ… Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export"
   },
   "outputs": [],
   "source": [
    "# Cell 11: Export Model to Drive\n",
    "from shutil import copytree, make_archive\n",
    "import os\n",
    "\n",
    "print(\"ðŸ’¾ Exporting model...\\n\")\n",
    "\n",
    "# Option 1: Save to Google Drive (if mounted)\n",
    "if MOUNT_DRIVE:\n",
    "    DRIVE_OUTPUT = '/content/drive/MyDrive/redsm5_models/best_model'\n",
    "    os.makedirs(os.path.dirname(DRIVE_OUTPUT), exist_ok=True)\n",
    "    copytree(BEST_CKPT, DRIVE_OUTPUT, dirs_exist_ok=True)\n",
    "    print(f\"âœ… Model saved to Google Drive: {DRIVE_OUTPUT}\")\n",
    "\n",
    "# Option 2: Create ZIP for download\n",
    "if BEST_CKPT.exists():\n",
    "    zip_path = OUTPUT_DIR / 'best_model'\n",
    "    make_archive(str(zip_path), 'zip', BEST_CKPT)\n",
    "    print(f\"âœ… Model packaged as: {zip_path}.zip\")\n",
    "    print(f\"   Size: {os.path.getsize(str(zip_path) + '.zip') / 1e6:.2f} MB\")\n",
    "    \n",
    "    # Uncomment to download automatically\n",
    "    # from google.colab import files\n",
    "    # files.download(str(zip_path) + '.zip')\n",
    "    # print(\"ðŸ“¥ Download started...\")\n",
    "else:\n",
    "    print(\"âŒ Best checkpoint not found\")\n",
    "\n",
    "# Also save key artifacts\n",
    "artifacts = ['thresholds.json', 'config_used.yaml', 'metrics_dev.json', 'metrics_test.json']\n",
    "print(\"\\nðŸ“¦ Key artifacts:\")\n",
    "for artifact in artifacts:\n",
    "    artifact_path = OUTPUT_DIR / artifact\n",
    "    if artifact_path.exists():\n",
    "        print(f\"   âœ… {artifact}\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  {artifact} (not found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inference"
   },
   "outputs": [],
   "source": [
    "# Cell 12: Inference Example\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"ðŸ”® Loading model for inference...\\n\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BEST_CKPT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BEST_CKPT)\n",
    "model.eval()\n",
    "\n",
    "# Move to device\n",
    "if USE_TPU:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    device = xm.xla_device()\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Load thresholds\n",
    "thresholds_path = OUTPUT_DIR / 'thresholds.json'\n",
    "with open(thresholds_path) as f:\n",
    "    thresholds_data = json.load(f)\n",
    "    thresholds = torch.tensor(thresholds_data['thresholds']).to(device)\n",
    "\n",
    "print(\"âœ… Model loaded\\n\")\n",
    "\n",
    "# Define label names\n",
    "label_cols = [\n",
    "    'depressed_mood', 'diminished_interest', 'weight_appetite_change',\n",
    "    'sleep_disturbance', 'psychomotor', 'fatigue',\n",
    "    'worthlessness_guilt', 'concentration_indecision', 'suicidality'\n",
    "]\n",
    "\n",
    "def predict_symptoms(text):\n",
    "    \"\"\"Predict DSM-5 symptoms from text.\"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.sigmoid(outputs.logits).cpu()\n",
    "        preds = (probs > thresholds.cpu()).int()\n",
    "    \n",
    "    return probs[0], preds[0]\n",
    "\n",
    "# Example 1: Depressive symptoms\n",
    "print(\"ðŸ” Example 1: Depression-related text\")\n",
    "text1 = \"I feel so sad and hopeless. I can't sleep and have no energy to do anything. Nothing brings me joy anymore.\"\n",
    "probs, preds = predict_symptoms(text1)\n",
    "\n",
    "print(f\"\\nText: {text1}\")\n",
    "print(\"\\nPredicted Symptoms:\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    if preds[i] == 1:\n",
    "        print(f\"  âœ“ {label.replace('_', ' ').title()} (prob: {probs[i]:.3f})\")\n",
    "\n",
    "# Example 2: Neutral text\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ” Example 2: Neutral text\")\n",
    "text2 = \"I went to the store today and bought some groceries. The weather was nice.\"\n",
    "probs, preds = predict_symptoms(text2)\n",
    "\n",
    "print(f\"\\nText: {text2}\")\n",
    "print(\"\\nPredicted Symptoms:\")\n",
    "detected = False\n",
    "for i, label in enumerate(label_cols):\n",
    "    if preds[i] == 1:\n",
    "        print(f\"  âœ“ {label.replace('_', ' ').title()} (prob: {probs[i]:.3f})\")\n",
    "        detected = True\n",
    "if not detected:\n",
    "    print(\"  (No symptoms detected)\")\n",
    "\n",
    "# Example 3: Custom input\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ” Example 3: Try your own text!\")\n",
    "print(\"\\nModify the cell below to test your own text:\")\n",
    "print(\"\"\"\\ntext_custom = \"Your text here...\"\n",
    "probs, preds = predict_symptoms(text_custom)\n",
    "# ... process results ...\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## ðŸŽ‰ Training Complete!\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Improve Performance:**\n",
    "   - Use larger models (7B/13B)\n",
    "   - Increase training epochs\n",
    "   - Use real ReDSM5 data\n",
    "   - Tune hyperparameters (learning rate, batch size)\n",
    "\n",
    "2. **Experiment with Settings:**\n",
    "   - Try different pooling strategies: `'max'`, `'mean'`, `'logit_sum'`\n",
    "   - Test Focal loss: `loss_type='focal'`\n",
    "   - Adjust class weighting: `'inv'`, `'sqrt_inv'`\n",
    "   - Use QLoRA for 13B models: `method='qlora'`\n",
    "\n",
    "3. **Production Deployment:**\n",
    "   - Save best model to Google Drive\n",
    "   - Export thresholds for inference\n",
    "   - Document your results\n",
    "   - Set up monitoring\n",
    "\n",
    "4. **Analysis:**\n",
    "   - Check per-label F1 scores\n",
    "   - Analyze false positives/negatives\n",
    "   - Review threshold values\n",
    "   - Validate on held-out data\n",
    "\n",
    "### ðŸ“š Resources\n",
    "\n",
    "- **GitHub:** https://github.com/OscarTsao/LLM_Agents_ReDSM5\n",
    "- **Paper:** [ReDSM5 Dataset](https://arxiv.org/abs/xxxx.xxxxx)\n",
    "- **Documentation:** See `README.md` in repository\n",
    "\n",
    "### ðŸ’¡ Tips\n",
    "\n",
    "- Use TPU for fastest training (Runtime > Change runtime type > TPU)\n",
    "- Mount Google Drive for persistent storage\n",
    "- Monitor training with wandb (`use_wandb=true`)\n",
    "- Save checkpoints regularly\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Fine-tuning! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ReDSM5_Training_Colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
